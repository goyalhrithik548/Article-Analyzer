{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0af20f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7496f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Not Found for URL ID blackassign0036\n",
      "Content Not Found for URL ID blackassign0049\n"
     ]
    }
   ],
   "source": [
    "# Function to read words from a file and return as a set\n",
    "def read_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return set(line.strip().lower() for line in file)\n",
    "\n",
    "# Function to count syllables in a word using a simple heuristic\n",
    "def count_syllables(word):\n",
    "    vowels = \"aeiou\"\n",
    "    word = word.lower().strip()\n",
    "    if word[0] in vowels:\n",
    "        count = 1\n",
    "    else:\n",
    "        count = 0\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if word.endswith(\"le\") and len(word) > 2 and word[-3] not in vowels:\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        count = 1\n",
    "    return count\n",
    "\n",
    "# Function to perform text analysis\n",
    "def analyze_text(article_content, pos_words, neg_words, stop_words, pronoun_list):\n",
    "    words = nltk.word_tokenize(article_content.lower())\n",
    "    sentences = nltk.sent_tokenize(article_content)\n",
    "    \n",
    "    punctuation_chars = set(string.punctuation)\n",
    "    \n",
    "    analysis_words = {word.strip() for word in words if word not in stop_words and word not in punctuation_chars}\n",
    "    \n",
    "    pos_score = sum(1 for word in analysis_words if word in pos_words)\n",
    "    neg_score = sum(1 for word in analysis_words if word in neg_words)\n",
    "    \n",
    "    neg_score = -neg_score\n",
    "    \n",
    "    word_count = len([word for word in analysis_words if word not in stop_words])\n",
    "    char_count = sum(len(word) for word in analysis_words)\n",
    "    \n",
    "    pol_score = (pos_score - neg_score) / ((pos_score + neg_score) + 0.000001)\n",
    "    sub_score = (pos_score + neg_score) / (word_count + 0.000001)\n",
    "    \n",
    "    pron_count = sum(1 for word in words if word in pronoun_list)\n",
    "    \n",
    "    avg_sen_len = round(word_count / len(sentences))\n",
    "    avg_word_len = round(char_count / word_count)\n",
    "    \n",
    "    avg_num_words_sentence = round(word_count / len(sentences))\n",
    "    \n",
    "    complex_words = sum(1 for word in analysis_words if count_syllables(word) >= 3)\n",
    "    percentage_complex_words = complex_words / word_count\n",
    "    \n",
    "    fog_index = 0.4 * (avg_sen_len + percentage_complex_words)\n",
    "    \n",
    "    syllable_per_word = round(sum(count_syllables(word) for word in analysis_words) / word_count)\n",
    "    \n",
    "    return {\n",
    "        'POSITIVE SCORE': pos_score,\n",
    "        'NEGATIVE SCORE': neg_score,\n",
    "        'POLARITY SCORE': pol_score,\n",
    "        'SUBJECTIVITY SCORE': sub_score,\n",
    "        'AVG SENTENCE LENGTH': avg_sen_len,\n",
    "        'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "        'FOG INDEX': fog_index,\n",
    "        'AVG NUMBER OF WORDS PER SENTENCE': avg_num_words_sentence,\n",
    "        'COMPLEX WORD COUNT': complex_words,\n",
    "        'WORD COUNT': word_count,\n",
    "        'SYLLABLE PER WORD': syllable_per_word,\n",
    "        'PERSONAL PRONOUNS': pron_count,\n",
    "        'AVG WORD LENGTH': avg_word_len\n",
    "    }\n",
    "\n",
    "# Main processing function\n",
    "def process_articles(input_file, output_file):\n",
    "    input_df = pd.read_excel(input_file)\n",
    "    \n",
    "    pos_words = read_words('positive-words.txt')\n",
    "    neg_words = read_words('negative-words.txt')\n",
    "    stop_words = read_words('StopWords.txt')\n",
    "    pronoun_list = ['i', 'we', 'my', 'ours', 'us']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for url, url_id in zip(input_df['URL'], input_df['URL_ID']):\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            \n",
    "            article = soup.find('div', class_='td-post-content')\n",
    "            if not article:\n",
    "                print(f\"Content Not Found for URL ID {url_id}\")\n",
    "                continue\n",
    "            \n",
    "            article_content = article.get_text(separator='\\n', strip=True)\n",
    "            article_title = soup.find('title').get_text()\n",
    "            \n",
    "            # Save article to a text file\n",
    "            with open(f'{url_id}.txt', 'w', encoding='utf-8') as file:\n",
    "                file.write(article_title + '\\n' + article_content)\n",
    "            \n",
    "            # Perform text analysis\n",
    "            analysis = analyze_text(article_content, pos_words, neg_words, stop_words, pronoun_list)\n",
    "            \n",
    "            # Add results to the list\n",
    "            result = {'URL_ID': url_id, 'URL': url}\n",
    "            result.update(analysis)\n",
    "            results.append(result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process URL {url}: {e}\")\n",
    "    \n",
    "    # Create a DataFrame with the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save the DataFrame to an Excel file\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "\n",
    "# Run the main processing function\n",
    "process_articles('Input.xlsx', 'Output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052f423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797d1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34856f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
